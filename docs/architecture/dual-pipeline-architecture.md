# Dual Pipeline Architecture

## Overview

The Phoenix (SA-OMF) project employs a dual pipeline architecture that is fundamental to its self-adaptive capabilities. This architecture separates the system into two interconnected pipelines:

1. **Data Pipeline**: Processes and transforms telemetry data (metrics)
2. **Control Pipeline**: Monitors system behavior and adjusts the data pipeline configuration 

This separation of concerns allows the system to adapt to changing conditions while maintaining clean boundaries between processing and control logic.

## Architecture Diagram

```
┌───────────────────────────────────────────────────────────────────┐
│                       DATA PIPELINE                                │
│                                                                   │
│  ┌─────────┐   ┌──────────────┐   ┌──────────────┐   ┌─────────┐  │
│  │ Metrics │   │  Processors  │   │  Processors  │   │ Metrics │  │
│  │ Input   ├──►│ (Updateable) ├──►│ (Updateable) ├──►│ Output  │  │
│  │         │   │              │   │              │   │         │  │
│  └─────────┘   └──────┬───────┘   └──────┬───────┘   └─────────┘  │
│                       │                  │                        │
└───────────────────────┼──────────────────┼────────────────────────┘
                        │                  │
                        │ Self-Metrics     │ Self-Metrics
                        ▼                  ▼
┌───────────────────────────────────────────────────────────────────┐
│                     CONTROL PIPELINE                               │
│                                                                   │
│  ┌─────────┐   ┌──────────────┐   ┌──────────────┐   ┌─────────┐  │
│  │ Metrics │   │    KPI       │   │    PID       │   │ Config  │  │
│  │ Monitor ├──►│  Calculator  ├──►│ Controllers  ├──►│ Patches │  │
│  │         │   │              │   │              │   │         │  │
│  └─────────┘   └──────────────┘   └──────────────┘   └────┬────┘  │
│                                                           │       │
└───────────────────────────────────────────────────────────┼───────┘
                                                            │
                                          Configuration     │
                                             Updates        │
                                                            ▼
                                       ┌────────────────────────────┐
                                       │    PIC Control Extension   │
                                       │                            │
                                       │  ┌─────────────────────┐   │
                                       │  │  Policy Management  │   │
                                       │  └─────────────────────┘   │
                                       │  ┌─────────────────────┐   │
                                       │  │ Safety Monitoring   │   │
                                       │  └─────────────────────┘   │
                                       └────────────────────────────┘
```

## Key Components

### Data Pipeline

1. **Metrics Input**
   - Ingests telemetry data from various sources
   - Typically based on OpenTelemetry Collector receivers

2. **Updateable Processors**
   - Implement the `UpdateableProcessor` interface
   - Process metrics while allowing dynamic reconfiguration
   - Examples: `adaptive_topk`, `priority_tagger`, `cardinality_guardian`
   
3. **Metrics Output**
   - Forwards processed metrics to destination systems
   - Based on OpenTelemetry exporters

### Control Pipeline

1. **Metrics Monitor**
   - Collects self-metrics from processors
   - Aggregates data for KPI calculation
   - Detects anomalies and performance issues

2. **KPI Calculator**
   - Computes Key Performance Indicators
   - Calculates error between current and target values
   - Determines when adjustments are needed

3. **PID Controllers**
   - Apply proportional, integral, and derivative control
   - Generate controlled adjustments based on error
   - Prevent oscillation and instability

4. **Config Patches**
   - Structured configuration change proposals
   - Include metadata like reason, severity, and TTL
   - Generated by the `adaptive_pid` processor

### Interconnection Layer

1. **PIC Control Extension**
   - Central governance layer for configuration changes
   - Applies and validates configuration patches
   - Enforces safety limits and policy constraints
   - Manages the registry of updateable processors

2. **PIC Connector**
   - Connects the PID controller output to configuration changes
   - Translates control signals into configuration patches
   - Handles communication between pipelines

## Data Flow

### Data Processing Flow

1. Metrics enter the system through the input pipeline
2. They flow through a series of updateable processors
3. Each processor performs its specific transformation:
   - `priority_tagger`: Tags resources with priority levels
   - `adaptive_topk`: Dynamically filters to the most important resources
   - `cardinality_guardian`: Controls metric cardinality
4. Processed metrics exit through exporters to destination systems
5. Self-metrics are emitted to monitor processor behavior

### Control Flow

1. Self-metrics are collected from processors
2. KPIs are calculated from these metrics
3. PID controllers compute error and required adjustments
4. Controllers generate configuration patches
5. PIC connector extracts patches and forwards to the control extension
6. PIC control extension validates and applies patches
7. Processors receive configuration updates
8. Processors adjust their behavior based on new configuration

## Feedback Loops

The dual pipeline architecture creates multiple feedback loops:

1. **Fast Loop**: Within the data pipeline, processors can make immediate local adjustments
2. **Medium Loop**: The control pipeline makes systematic adjustments to processor configurations
3. **Slow Loop**: Policy updates can reconfigure the entire system's goals and constraints

These loops operate at different time scales to provide both responsiveness and stability.

## Key Design Principles

### 1. Separation of Concerns

Data processing and control logic are completely separated, making the system:
- Easier to reason about
- More maintainable
- Less prone to unintended interactions

### 2. Self-Regulation

The system constantly monitors its own behavior and adjusts itself:
- No external intervention needed for routine adjustments
- Automatic adaptation to changing conditions
- Self-healing capability when parameters drift

### 3. Stability Guarantees

PID controllers provide stability by design:
- Prevents excessive oscillation
- Avoids overreaction to transient issues
- Ensures smooth transitions between states

### 4. Safety Boundaries

Multiple safeguards prevent the system from entering unsafe states:
- Hard limits on configuration parameters
- Rate limiting of changes
- Fallback to safe defaults when needed
- Hysteresis to prevent rapid oscillation

## Implementation Guidelines

When implementing components in the dual pipeline architecture:

1. **Data Pipeline Components**
   - Focus on efficient data processing
   - Implement the `UpdateableProcessor` interface
   - Emit self-metrics to enable monitoring
   - Apply received configuration changes

2. **Control Pipeline Components**
   - Focus on analysis and decision making
   - Avoid directly processing high-volume data
   - Generate precise, targeted configuration changes
   - Consider stability implications of changes

3. **Connection Components**
   - Ensure reliable delivery of configuration changes
   - Validate changes before application
   - Provide clear tracing between cause and effect
   - Implement fallback mechanisms for failures

## Benefits of Dual Pipeline Architecture

1. **Adaptability**: System adjusts to changing conditions without manual intervention
2. **Resilience**: Can recover from anomalies and shifting workloads
3. **Efficiency**: Resources are focused where they provide most value
4. **Scalability**: Control overhead remains constant regardless of data volume
5. **Observability**: Clear separation makes it easier to monitor and debug

## Challenges and Solutions

### Challenge: Control Loop Stability

**Solution**:
- Use PID controllers with carefully tuned parameters
- Implement anti-windup protection
- Add hysteresis to prevent oscillation
- Test extensively under varying conditions

### Challenge: Configuration Propagation

**Solution**:
- Centralize configuration management in PIC control extension
- Use well-defined ConfigPatch objects
- Implement validation at multiple levels
- Add TTL to ensure stale configurations expire

### Challenge: Performance Overhead

**Solution**:
- Keep control pipeline logic separate from data path
- Sample metrics for control decisions when volumes are high
- Process control logic at lower frequency than data
- Optimize critical data path components

## Future Extensions

The dual pipeline architecture can be extended in several ways:

1. **Hierarchical Control**: Add multiple levels of control loops
2. **Federated Architecture**: Coordinate between multiple instances
3. **Machine Learning Integration**: Replace or augment PID controllers with ML models
4. **Predictive Adaptation**: Add forecasting to anticipate needed changes

## Conclusion

The dual pipeline architecture provides a solid foundation for building self-adaptive systems. By separating data processing from control logic, it enables complex adaptation behaviors while maintaining system stability and performance.